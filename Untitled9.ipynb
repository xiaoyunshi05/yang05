{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa45f58-b5a5-4ef5-9926-e1599a09f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path as path\n",
    "import gzip\n",
    "from typing import Tuple,List\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ecc279-5722-41ab-8823-641c6088ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为后续的数据加载操作提供必要的路径和文件名信息。\n",
    "dataset_folder = 'data/MNIST/raw/'\n",
    "files_name = {\n",
    "    'train_img': 'train-images-idx3-ubyte.gz',\n",
    "    'train_label': 'train-labels-idx1-ubyte.gz',\n",
    "    'vali_img': 't10k-images-idx3-ubyte.gz',\n",
    "    'vali_label': 't10k-labels-idx1-ubyte.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2077c41c-b6f4-4020-bfe1-d0ac5a82e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从MNIST数据集中读取图像和标签数据。\n",
    "def dataloader(files_name) -> Tuple:\n",
    "    with gzip.open(path.join(dataset_folder, files_name['train_img']), mode='rb') as data:\n",
    "        train_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n",
    "    # 加载训练集 标签\n",
    "    with gzip.open(path.join(dataset_folder, files_name['train_label']), mode='rb') as label:\n",
    "        train_label = torch.frombuffer(label.read(), dtype=torch.uint8, offset=8)\n",
    "    # 加载验证集 图片\n",
    "    with gzip.open(path.join(dataset_folder, files_name['vali_img']), mode='rb') as data:\n",
    "        test_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n",
    "    # 加载验证集 label\n",
    "    with gzip.open(path.join(dataset_folder, files_name['vali_label']), mode='rb') as label:\n",
    "        test_label = torch.frombuffer(label.read(), dtype=torch.uint8, offset=8)\n",
    "    return (train_img, train_label),(test_img, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59393280-6df8-44f2-bd55-defc96682f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30399\\AppData\\Local\\Temp\\ipykernel_21580\\96169694.py:4: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:1550.)\n",
      "  train_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNIST_dataset(Dataset):\n",
    "    def __init__(self, data: List, label: List):\n",
    "        self.__data = data\n",
    "        self.__label = label\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if not item < self.__len__():\n",
    "            return f'Error, index {item} is out of range'\n",
    "        return self.__data[item], self.__label[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__data)\n",
    "# 读取数据\n",
    "train_data,test_data = dataloader(files_name)\n",
    "# 将数据封装为 MNIST 类\n",
    "train_dataset = MNIST_dataset(*train_data)\n",
    "test_dataset = MNIST_dataset(*test_data)\n",
    "len(train_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa26689-186b-427d-aea4-d87c07c16d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5))\n",
    "        self.conv1 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
    "        self.pool0 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        self.linear0 = nn.Linear(16*4*4, 120)\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x):\n",
    "        output = self.conv0(x)\n",
    "        output = self.pool0(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.flatten(output)\n",
    "        output = self.linear0(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "\n",
    "net = NetWork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626c5779-5efe-48f9-acc0-b87de049a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loss, train_iter, test_iter, optimizer, epochs, device):\n",
    "    net = net.to(device)\n",
    "    epoch_losses = [] #用于存储每个批次的损失值，以便计算平均损失。\n",
    "    train_correct = 0#用于记录训练集中正确预测的样本数\n",
    "    train_len = 0\n",
    "    test_correct = 0#记录测试集中正确预测的样本数。\n",
    "    test_len = 0\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        net.train()\n",
    "        epoch_losses.clear()\n",
    "        for img, label in train_iter:\n",
    "            img, label = img.to(device, dtype=torch.float), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(img)\n",
    "            l = loss(output, label)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(l.item())\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            train_correct += pred.eq(label.view_as(pred)).sum().item()#label.view_as(pred) 的作用是将 label 的形状调整为与 pred 相同，以便进行比较\n",
    "            train_len += len(label)\n",
    "\n",
    "        train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        train_acc = train_correct / train_len * 100.0\n",
    "        print(f'-----------epoch: {epoch} start --------------')\n",
    "        print(f'epoch: {epoch} train loss: {train_loss}')\n",
    "        print(f'epoch: {epoch} train acc: {train_acc}')\n",
    "\n",
    "        epoch_losses.clear()\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for img, label in test_iter:\n",
    "                img, label = img.to(device, dtype=torch.float), label.to(device)\n",
    "                test_output = net(img)\n",
    "                l = loss(test_output, label)\n",
    "                epoch_losses.append(l.item())\n",
    "                test_pred = test_output.argmax(dim=1, keepdim=True)\n",
    "                test_correct += (test_pred.squeeze() == label).sum().item()\n",
    "                test_len += len(label)\n",
    "\n",
    "            test_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            test_acc = test_correct / test_len * 100.0\n",
    "            print(f'epoch: {epoch} test loss: {test_loss}')\n",
    "            print(f'epoch: {epoch} test acc: {test_acc}')\n",
    "            print(f'-----------epoch: {epoch} end --------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6604ab9b-5b07-4e55-9de9-27183e301fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------epoch: 1 start --------------\n",
      "epoch: 1 train loss: 0.7497243150988594\n",
      "epoch: 1 train acc: 81.75833333333333\n",
      "epoch: 1 test loss: 0.43234172335877086\n",
      "epoch: 1 test acc: 93.73\n",
      "-----------epoch: 1 end --------------\n",
      "-----------epoch: 2 start --------------\n",
      "epoch: 2 train loss: 0.4519704268684456\n",
      "epoch: 2 train acc: 87.44583333333334\n",
      "epoch: 2 test loss: 0.418471088106744\n",
      "epoch: 2 test acc: 93.975\n",
      "-----------epoch: 2 end --------------\n",
      "-----------epoch: 3 start --------------\n",
      "epoch: 3 train loss: 0.42379732068494586\n",
      "epoch: 3 train acc: 89.55111111111111\n",
      "epoch: 3 test loss: 0.35825194809184174\n",
      "epoch: 3 test acc: 94.65333333333334\n",
      "-----------epoch: 3 end --------------\n",
      "-----------epoch: 4 start --------------\n",
      "epoch: 4 train loss: 0.41032715474879367\n",
      "epoch: 4 train acc: 90.75208333333333\n",
      "epoch: 4 test loss: 0.33877875032264276\n",
      "epoch: 4 test acc: 95.155\n",
      "-----------epoch: 4 end --------------\n",
      "-----------epoch: 5 start --------------\n",
      "epoch: 5 train loss: 0.39952217264781553\n",
      "epoch: 5 train acc: 91.532\n",
      "epoch: 5 test loss: 0.3824847356758022\n",
      "epoch: 5 test acc: 95.208\n",
      "-----------epoch: 5 end --------------\n",
      "-----------epoch: 6 start --------------\n",
      "epoch: 6 train loss: 0.3915079230418351\n",
      "epoch: 6 train acc: 92.11805555555556\n",
      "epoch: 6 test loss: 0.36895587775835303\n",
      "epoch: 6 test acc: 95.28333333333333\n",
      "-----------epoch: 6 end --------------\n",
      "-----------epoch: 7 start --------------\n",
      "epoch: 7 train loss: 0.38964007867884937\n",
      "epoch: 7 train acc: 92.54404761904762\n",
      "epoch: 7 test loss: 0.35461238467255607\n",
      "epoch: 7 test acc: 95.42\n",
      "-----------epoch: 7 end --------------\n",
      "-----------epoch: 8 start --------------\n",
      "epoch: 8 train loss: 0.3891116560189\n",
      "epoch: 8 train acc: 92.874375\n",
      "epoch: 8 test loss: 0.3480589926732762\n",
      "epoch: 8 test acc: 95.54375\n",
      "-----------epoch: 8 end --------------\n",
      "-----------epoch: 9 start --------------\n",
      "epoch: 9 train loss: 0.3851293170106198\n",
      "epoch: 9 train acc: 93.15296296296296\n",
      "epoch: 9 test loss: 0.3749601749034744\n",
      "epoch: 9 test acc: 95.5988888888889\n",
      "-----------epoch: 9 end --------------\n",
      "-----------epoch: 10 start --------------\n",
      "epoch: 10 train loss: 0.3846161671040444\n",
      "epoch: 10 train acc: 93.3885\n",
      "epoch: 10 test loss: 0.33638188025071286\n",
      "epoch: 10 test acc: 95.732\n",
      "-----------epoch: 10 end --------------\n"
     ]
    }
   ],
   "source": [
    "net = NetWork()\n",
    "batch_size = 16\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 10\n",
    "loss = nn.CrossEntropyLoss()#衡量模型预测结果与真实标签之间的差异程度。\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "train(net, loss, train_iter, test_iter, optimizer, num_epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b609f-b4f7-4b96-b353-bbca5708d077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
